@inproceedings {185128,
  author = {Elie Bursztein and Jonathan Aigrain and Angelika Moscicki and John C. Mitchell},
  title = {The End is Nigh: Generic Solving of Text-based CAPTCHAs},
  booktitle = {8th {USENIX} Workshop on Offensive Technologies ({WOOT} 14)},
  year = {2014},
  address = {San Diego, CA},
  url = {https://www.usenix.org/conference/woot14/workshop-program/presentation/bursztein},
  publisher = {{USENIX} Association},
}

@misc{ wiki:captcha,
  author = "{Wikipedia contributors}",
  title = "CAPTCHA --- {W}ikipedia{,} The Free Encyclopedia",
  year = "2018",
  url = "https://en.wikipedia.org/wiki/CAPTCHA#Characteristics",
  note = "[Online; accessed 27-December-2018]"
}
 
@misc{Stark_captcharecognition,
  author = {Fabian Stark and Rudolph Triebel and Daniel Cremers},
  title = {CAPTCHA Recognition with Active Deep Learning},
  year = {}
}

@inproceedings{Mori,
  doi = {10.1109/cvpr.2003.1211347},
  url = {https://doi.org/10.1109/cvpr.2003.1211347},
  publisher = {{IEEE} Comput. Soc},
  author = {G. Mori and J. Malik},
  title = {Recognizing objects in adversarial clutter: breaking a visual {CAPTCHA}},
  booktitle = {2003 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition,  2003. Proceedings.}
}

@incollection{NIPS2004_2571,
  title = {Using Machine Learning to Break Visual Human Interaction Proofs (HIPs)},
  author = {Kumar Chellapilla and Patrice Y. Simard},
  booktitle = {Advances in Neural Information Processing Systems 17},
  editor = {L. K. Saul and Y. Weiss and L. Bottou},
  pages = {265--272},
  year = {2005},
  publisher = {MIT Press},
  url = {http://papers.nips.cc/paper/2571-using-machine-learning-to-break-visual-human-interaction-proofs-hips.pdf}
}

@article{DBLP:journals/corr/CohenATS17,
  author    = {Gregory Cohen and
               Saeed Afshar and
               Jonathan Tapson and
               Andr{\'{e}} van Schaik},
  title     = {{EMNIST:} an extension of {MNIST} to handwritten letters},
  journal   = {CoRR},
  volume    = {abs/1702.05373},
  year      = {2017},
  url       = {http://arxiv.org/abs/1702.05373},
  archivePrefix = {arXiv},
  eprint    = {1702.05373},
  timestamp = {Mon, 13 Aug 2018 16:48:00 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/CohenATS17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Sivakorn2016,
  doi = {10.1109/eurosp.2016.37},
  url = {https://doi.org/10.1109/eurosp.2016.37},
  year  = {2016},
  month = {mar},
  publisher = {{IEEE}},
  author = {Suphannee Sivakorn and Iasonas Polakis and Angelos D. Keromytis},
  title = {I am Robot: (Deep) Learning to Break Semantic Image {CAPTCHAs}},
  booktitle = {2016 {IEEE} European Symposium on Security and Privacy ({EuroS}{\&}P)}
}

@inproceedings{Zhao:2018:TES:3270101.3270104,
 author = {Zhao, Binbin and Weng, Haiqin and Ji, Shouling and Chen, Jianhai and Wang, Ting and He, Qinming and Beyah, Reheem},
 title = {Towards Evaluating the Security of Real-World Deployed Image CAPTCHAs},
 booktitle = {Proceedings of the 11th ACM Workshop on Artificial Intelligence and Security},
 series = {AISec '18},
 year = {2018},
 isbn = {978-1-4503-6004-3},
 location = {Toronto, Canada},
 pages = {85--96},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3270101.3270104},
 doi = {10.1145/3270101.3270104},
 acmid = {3270104},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {captcha-solving services, deep learning, image captchas},
}

@article{George2017,
  doi = {10.1126/science.aag2612},
  url = {https://doi.org/10.1126/science.aag2612},
  year  = {2017},
  month = {oct},
  publisher = {American Association for the Advancement of Science ({AAAS})},
  volume = {358},
  number = {6368},
  pages = {eaag2612},
  author = {Dileep George and Wolfgang Lehrach and Ken Kansky and Miguel L{\'{a}}zaro-Gredilla and Christopher Laan and Bhaskara Marthi and Xinghua Lou and Zhaoshi Meng and Yi Liu and Huayan Wang and Alex Lavin and D. Scott Phoenix},
  title = {A generative vision model that trains with high data efficiency and breaks text-based {CAPTCHAs}},
  journal = {Science}
}

@inproceedings{Yan:2008:LAM:1455770.1455839,
 author = {Yan, Jeff and El Ahmad, Ahmad Salah},
 title = {A Low-cost Attack on a Microsoft Captcha},
 booktitle = {Proceedings of the 15th ACM Conference on Computer and Communications Security},
 series = {CCS '08},
 year = {2008},
 isbn = {978-1-59593-810-7},
 location = {Alexandria, Virginia, USA},
 pages = {543--554},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/1455770.1455839},
 doi = {10.1145/1455770.1455839},
 acmid = {1455839},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {captcha, internet security, robustness, segmentation attack, usability},
} 

@inproceedings{Yan2007,
  doi = {10.1109/acsac.2007.47},
  url = {https://doi.org/10.1109/acsac.2007.47},
  year  = {2007},
  month = {dec},
  publisher = {{IEEE}},
  author = {Jeff Yan and Ahmad Salah El Ahmad},
  title = {Breaking Visual {CAPTCHAs} with Naive Pattern Recognition Algorithms},
  booktitle = {Twenty-Third Annual Computer Security Applications Conference ({ACSAC} 2007)}
}

@inproceedings{Li:2010:BEC:1920261.1920288,
 author = {Li, Shujun and Shah, S. Amier Haider and Khan, M. Asad Usman and Khayam, Syed Ali and Sadeghi, Ahmad-Reza and Schmitz, Roland},
 title = {Breaking e-Banking CAPTCHAs},
 booktitle = {Proceedings of the 26th Annual Computer Security Applications Conference},
 series = {ACSAC '10},
 year = {2010},
 isbn = {978-1-4503-0133-6},
 location = {Austin, Texas, USA},
 pages = {171--180},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/1920261.1920288},
 doi = {10.1145/1920261.1920288},
 acmid = {1920288},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {CAPTCHA, e-banking, electronic commerce, malware, man-in-the-middle attack},
} 

@InProceedings{10.1007/978-3-319-10590-1_53,
author="Zeiler, Matthew D.
and Fergus, Rob",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="Visualizing and Understanding Convolutional Networks",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="818--833",
abstract="Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.",
isbn="978-3-319-10590-1"
}

@article{Yosinski2015UnderstandingNN,
  title={Understanding Neural Networks Through Deep Visualization},
  author={Jason Yosinski and Jeff Clune and Anh Mai Nguyen and Thomas J. Fuchs and Hod Lipson},
  journal={CoRR},
  year={2015},
  volume={abs/1506.06579}
}

@inproceedings{Selvaraju2017,
  doi = {10.1109/iccv.2017.74},
  url = {https://doi.org/10.1109/iccv.2017.74},
  year  = {2017},
  month = {oct},
  publisher = {{IEEE}},
  author = {Ramprasaath R. Selvaraju and Michael Cogswell and Abhishek Das and Ramakrishna Vedantam and Devi Parikh and Dhruv Batra},
  title = {Grad-{CAM}: Visual Explanations from Deep Networks via Gradient-Based Localization},
  booktitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})}
}